{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YglMsqkIDbIT",
        "outputId": "71acc05f-52e0-4f9d-dc6e-883a20a945a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aisuite in /usr/local/lib/python3.10/dist-packages (0.1.6)\n"
          ]
        }
      ],
      "source": [
        "# Install AI Suite\n",
        "!pip install aisuite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade groq\n",
        "!pip install --upgrade huggingface\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djdsATwrEs_y",
        "outputId": "661b2b04-f9bb-4284-e270-71fab89672e1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\n",
            "Requirement already satisfied: huggingface in /usr/local/lib/python3.10/dist-packages (0.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pprint import pprint as pp\n",
        "# Set a custom width for pretty-printing\n",
        "def pprint(data, width=80):\n",
        "    \"\"\"Pretty print data with a specified width.\"\"\"\n",
        "    pp(data, width=width)# List of model identifiers to query"
      ],
      "metadata": {
        "id": "rQNklEEnDzcH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "os.environ['GROQ_API_KEY'] = getpass('GROQ_API_KEY')\n",
        "os.environ['HUGGINGFACE_TOKEN'] = getpass('HUGGINGFACE_TOKEN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTXkCwdzD8Kd",
        "outputId": "458d6bf3-3b9c-48db-c15a-d39a54a40d4f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GROQ_API_KEY··········\n",
            "HUGGINGFACE_TOKEN··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aisuite as ai  # Assuming this library is correctly installed\n",
        "\n",
        "client = ai.Client()\n",
        "models = [\"groq:llama-3.2-3b-preview\", \"huggingface:Llama-3.1-8B-Instruct\"]\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Respond in Pirate English.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=0.75\n",
        "        )\n",
        "        print(f\"Response from model '{model}':\\n{response.choices[0].message.content}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error using model '{model}': {e}\")  # Catch and report any errors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbkOldrWEahb",
        "outputId": "12cf84e3-97db-434f-9b0d-40d22f9106ec"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from model 'groq:llama-3.2-3b-preview':\n",
            "Yer lookin' fer a joke, eh? Alright then, matey, here be one fer ye:\n",
            "\n",
            "Why did the scurvy dog bring a ladder to the bar?\n",
            "\n",
            "(pause fer dramatic effect)\n",
            "\n",
            "Because he heard the drinks were on the house! Arrr!\n",
            "\n",
            "Error using model 'huggingface:Llama-3.1-8B-Instruct': Hugging Face request failed: Client error '400 Bad Request' for url 'https://api-inference.huggingface.co/models/Llama-3.1-8B-Instruct/v1/chat/completions'\n",
            "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400\n"
          ]
        }
      ]
    }
  ]
}