{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LangChain Function/Tool Calling Calculator**"
      ],
      "metadata": {
        "id": "d1OHsUObpNdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple project that integrates LangChain's tool-calling capabilities with a conversational agent to perform basic arithmetic operations. This project demonstrates how to use LangChain's initialize_agent function to create a dynamic agent capable of interpreting and executing mathematical queries."
      ],
      "metadata": {
        "id": "4756mp94pFnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Install Dependencies**"
      ],
      "metadata": {
        "id": "3ccBorgopqYo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwDwLFIt6OPa",
        "outputId": "9057ff17-9472-41b7-cfe0-2efabcf88ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Set Your Gemini API Key**"
      ],
      "metadata": {
        "id": "mY2n_amPps7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n"
      ],
      "metadata": {
        "id": "tNekwnAjNMqQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "_C0uRz1RNgsC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### **Initialize the Gemini language model using the provided API key and model name.**"
      ],
      "metadata": {
        "id": "F2Z2SPr5qylq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    api_key=GOOGLE_API_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "G5Jx7SNENs1S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test Gemini LLM**\n",
        "Tests the Gemini model by asking a simple question (\"What is the capital of France?\")."
      ],
      "metadata": {
        "id": "dIRnXdJ_q-9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"What is the capital of France?\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "muU0JRz3bVzC",
        "outputId": "753de8fc-b538-4585-851e-9d070f14f143"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Paris'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define the Tools**\n",
        "Defines several Python functions as tools for the agent. These functions perform basic arithmetic operations like addition, subtraction, multiplication, division, power, and square root."
      ],
      "metadata": {
        "id": "u_DhRW9op84W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def add(a: float, b: float) -> float:\n",
        "    \"\"\"Adds two numbers.\n",
        "\n",
        "    Args:\n",
        "        a: First number\n",
        "        b: Second number\n",
        "\n",
        "    Returns:\n",
        "        The sum of a and b.\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "@tool\n",
        "def subtract(a: float, b: float) -> float:\n",
        "    \"\"\"Subtracts the second number from the first.\n",
        "\n",
        "    Args:\n",
        "        a: First number\n",
        "        b: Second number\n",
        "\n",
        "    Returns:\n",
        "        The result of a - b.\n",
        "    \"\"\"\n",
        "    return a - b\n",
        "\n",
        "\n",
        "@tool\n",
        "def multiply(a: float, b: float) -> float:\n",
        "    \"\"\"Multiplies two numbers.\n",
        "\n",
        "    Args:\n",
        "        a: First number\n",
        "        b: Second number\n",
        "\n",
        "    Returns:\n",
        "        The product of a and b.\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "@tool\n",
        "def divide(a: float, b: float) -> float:\n",
        "    \"\"\"Divides the first number by the second.\n",
        "\n",
        "    Args:\n",
        "        a: First number\n",
        "        b: Second number\n",
        "\n",
        "    Returns:\n",
        "        The result of a / b.\n",
        "\n",
        "    Note:\n",
        "        If b is 0, it will return an error message.\n",
        "    \"\"\"\n",
        "    if b == 0:\n",
        "        return \"Error: Division by zero is not allowed.\"\n",
        "    return a / b\n",
        "\n",
        "\n",
        "@tool\n",
        "def power(base: float, exponent: float) -> float:\n",
        "    \"\"\"Raises a number to the power of the given exponent.\n",
        "\n",
        "    Args:\n",
        "        base: The base number\n",
        "        exponent: The power to raise the base to\n",
        "\n",
        "    Returns:\n",
        "        The result of base^exponent.\n",
        "    \"\"\"\n",
        "    return base ** exponent\n",
        "\n",
        "\n",
        "@tool\n",
        "def sqrt(number: float) -> float:\n",
        "    \"\"\"Calculates the square root of a number.\n",
        "\n",
        "    Args:\n",
        "        number: The number to find the square root of\n",
        "\n",
        "    Returns:\n",
        "        The square root of the number.\n",
        "    \"\"\"\n",
        "    if number < 0:\n",
        "        return \"Error: Cannot calculate the square root of a negative number.\"\n",
        "    return number ** 0.5\n"
      ],
      "metadata": {
        "id": "SNbgEY0BP8TK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gather Tools**\n",
        " Gathers the defined tools into a list to be used by the agent."
      ],
      "metadata": {
        "id": "kg1rqVnPrlaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [add, subtract, multiply, divide, power, sqrt]"
      ],
      "metadata": {
        "id": "goFwY80eboFU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bind Tools and Test**"
      ],
      "metadata": {
        "id": "kyn4Vp0OrwkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "y_NICc-RRVGf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is 3 * 12?\"\n",
        "\n",
        "llm.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81DcJd2QRhjn",
        "outputId": "ee356b12-e619-4846-85a0-28b652b291fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='3 * 12 = 36', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-28e7e843-4366-454b-8dd2-bb73145f57f2-0', usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tool Calling Workflow**\n",
        "Demonstrates the tool-calling workflow using HumanMessage and ToolMessage for interaction with the LLM and tools. It processes the query, selects the appropriate tool, executes it, and appends the tool's output to the message history.\n"
      ],
      "metadata": {
        "id": "BZ5JwQvJr-11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is 3 * 12?\"\n",
        "\n",
        "llm_with_tools.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UupC3snWcYuY",
        "outputId": "fdf015c2-5347-4b47-8849-77ce8f8302fc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"a\": 3.0, \"b\": 12.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-a869e78c-27dd-45da-ab70-893ede8723a9-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3.0, 'b': 12.0}, 'id': '61d4c3b6-51c0-4434-b1ab-0aedb3e10da7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 492, 'output_tokens': 3, 'total_tokens': 495, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Get Final Response**\n",
        " Sends the final message history to the LLM to obtain the final response, which should contain the result of the calculation"
      ],
      "metadata": {
        "id": "eGmwwEdLsVc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, ToolMessage\n",
        "\n",
        "messages = [HumanMessage(query)]\n",
        "ai_msg = llm_with_tools.invoke(messages)\n",
        "messages.append(ai_msg)"
      ],
      "metadata": {
        "id": "kDNWagfQR_Bv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tool_call in ai_msg.tool_calls:\n",
        "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
        "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
        "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGyddzNOSH_w",
        "outputId": "a655728c-054a-41fe-ff78-28e835b3f9e8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is 3 * 12?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"a\": 3.0, \"b\": 12.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-93cf511d-0708-4f87-b037-27dafe9b5f68-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3.0, 'b': 12.0}, 'id': '89019b1e-56df-4c92-a53d-b0f2cc2ba30f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 492, 'output_tokens': 3, 'total_tokens': 495, 'input_token_details': {'cache_read': 0}}),\n",
              " ToolMessage(content='36.0', tool_call_id='89019b1e-56df-4c92-a53d-b0f2cc2ba30f')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm_with_tools.invoke(messages)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV7dqliXSki2",
        "outputId": "9d9b4b13-d747-4af4-febc-1eb85c5f2d4e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='36.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-61ff3815-46b4-4e8f-b7c7-c3010b177afa-0', usage_metadata={'input_tokens': 527, 'output_tokens': 3, 'total_tokens': 530, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### **Displays the agent's response using Markdown for better formatting**"
      ],
      "metadata": {
        "id": "wPFtOm0kssro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "eCxa5-ZqduUn",
        "outputId": "f0077d5f-24a5-48b1-c3b2-fa00173e1f40"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "36."
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import Memory**"
      ],
      "metadata": {
        "id": "-AfaSezztCoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "9Rw2TzpqfCje"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### **Initialize the conversation memory to store the conversation history**"
      ],
      "metadata": {
        "id": "yslIzkTJtOr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZrBXR0Ph3wH",
        "outputId": "21dfde1b-a869-4530-d0da-bfe7efdc6c4f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-4cbb8db76ddd>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Initialize the Agent**\n",
        " Initializes the LangChain agent with the defined tools, language model, agent type, and configuration parameters."
      ],
      "metadata": {
        "id": "ewyRrmXUqQKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "# Initialize the agent using LangChain's built-in function\n",
        "# Use StructuredChatZeroShotAgent instead of ZeroShotAgent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, # Changed to StructuredChatZeroShotAgent\n",
        "    callback_manager=None,\n",
        "    agent_kwargs={\"verbose\": True},  # Additional arguments like verbose mode\n",
        ")"
      ],
      "metadata": {
        "id": "8jNXNFl3iBVd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Start a Conversation**\n",
        "Demonstrates how to interact with the initialized agent by providing a query and printing the agent's response."
      ],
      "metadata": {
        "id": "ylW8kZDAqayT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User query\n",
        "query = \"What is 3 * 12?\"\n",
        "\n",
        "# Let the agent handle the query\n",
        "response = agent.run(query)\n",
        "\n",
        "# Output the response\n",
        "print(\"Agent's Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbEdTNEnjftH",
        "outputId": "2569fbfb-54d0-4023-b77a-804dd86ca855"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-4f681d69519c>:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = agent.run(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent's Response: 36\n"
          ]
        }
      ]
    }
  ]
}